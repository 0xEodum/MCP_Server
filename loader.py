#!/usr/bin/env python3
"""
index_medical_docs.py - –°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö JSON –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python index_medical_docs.py /path/to/json/folder
    python index_medical_docs.py /path/to/json/folder --recreate
"""

import sys
import argparse
import json
from pathlib import Path
from typing import List, Dict, Any

from medical_qdrant_api import MedicalQdrantStore
from medical_embedding_api import MedicalEmbedder
from medical_indexer import index_medical_documents


def find_json_files(folder_path: Path) -> List[Path]:
    """–ü–æ–∏—Å–∫ –≤—Å–µ—Ö JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ."""
    if not folder_path.exists():
        raise FileNotFoundError(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")

    json_files = list(folder_path.glob("*.json"))

    if not json_files:
        raise ValueError(f"JSON —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {folder_path}")

    return json_files


def validate_json_structure(file_path: Path) -> Dict[str, Any]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON —Ñ–∞–π–ª–∞."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = ['doc_title', 'mkb', 'sections']
        missing_fields = [field for field in required_fields if field not in data]

        if missing_fields:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing_fields}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã sections
        if not isinstance(data['sections'], list):
            raise ValueError("–ü–æ–ª–µ 'sections' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")

        valid_sections = 0
        for i, section in enumerate(data['sections']):
            if not isinstance(section, dict):
                print(f"–í–ù–ò–ú–ê–ù–ò–ï: –°–µ–∫—Ü–∏—è {i} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º –≤ {file_path.name}")
                continue

            if 'id' not in section or 'title' not in section or 'body' not in section:
                print(f"–í–ù–ò–ú–ê–ù–ò–ï: –°–µ–∫—Ü–∏—è {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –≤ {file_path.name}")
                continue

            if section.get('body', '').strip():
                valid_sections += 1

        print(f"‚úì {file_path.name}: {len(data['sections'])} —Å–µ–∫—Ü–∏–π, {valid_sections} —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º")
        return data

    except json.JSONDecodeError as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")


def analyze_documents(json_files: List[Path]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–¥ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π."""

    print("=" * 60)
    print("–ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í")
    print("=" * 60)

    total_docs = 0
    total_sections = 0
    total_content_sections = 0
    diseases = []
    icd_codes = set()

    for file_path in json_files:
        try:
            data = validate_json_structure(file_path)

            total_docs += 1
            diseases.append(data['doc_title'])

            # –ú–ö–ë –∫–æ–¥—ã
            for code in data.get('mkb', []):
                icd_codes.add(code)

            # –°–µ–∫—Ü–∏–∏
            doc_sections = len(data['sections'])
            doc_content_sections = sum(1 for s in data['sections'] if s.get('body', '').strip())

            total_sections += doc_sections
            total_content_sections += doc_content_sections

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {file_path.name}: {e}")
            continue

    print(f"\n–°–≤–æ–¥–∫–∞:")
    print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
    print(f"–í—Å–µ–≥–æ —Å–µ–∫—Ü–∏–π: {total_sections}")
    print(f"–°–µ–∫—Ü–∏–π —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º: {total_content_sections}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ú–ö–ë –∫–æ–¥–æ–≤: {len(icd_codes)}")

    if diseases:
        print(f"\n–ü–µ—Ä–≤—ã–µ 5 –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π:")
        for disease in diseases[:5]:
            print(f"  ‚Ä¢ {disease}")
        if len(diseases) > 5:
            print(f"  ... –∏ –µ—â–µ {len(diseases) - 5}")

    return {
        'total_docs': total_docs,
        'total_sections': total_sections,
        'total_content_sections': total_content_sections,
        'icd_codes': len(icd_codes),
        'diseases': diseases
    }


def main():
    parser = argparse.ArgumentParser(description='–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö JSON –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤')
    parser.add_argument('folder', help='–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å JSON —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--recreate', action='store_true',
                        help='–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (—É–¥–∞–ª–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ)')
    parser.add_argument('--qdrant-url', default='http://localhost:6333',
                        help='URL Qdrant —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--model', default='paraphrase-multilingual-MiniLM-L12-v2',
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤')
    parser.add_argument('--dry-run', action='store_true',
                        help='–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏')

    args = parser.parse_args()

    print("üè• –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"–ü–∞–ø–∫–∞: {args.folder}")
    print(f"Qdrant: {args.qdrant_url}")
    print(f"–ú–æ–¥–µ–ª—å: {args.model}")
    if args.recreate:
        print("‚ö†Ô∏è  –†–µ–∂–∏–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π!")
    print()

    try:
        # –ü–æ–∏—Å–∫ JSON —Ñ–∞–π–ª–æ–≤
        folder_path = Path(args.folder)
        json_files = find_json_files(folder_path)
        print(f"–ù–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤: {len(json_files)}")

        # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        analysis = analyze_documents(json_files)

        if args.dry_run:
            print("\nüìä –†–µ–∂–∏–º dry-run. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.")
            return

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        if args.recreate:
            confirm = input("\n–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏? –í—Å–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã! (yes/no): ")
            if confirm.lower() != 'yes':
                print("–û—Ç–º–µ–Ω–µ–Ω–æ.")
                return

        print("\n" + "=" * 60)
        print("–ò–ù–î–ï–ö–°–ê–¶–ò–Ø")
        print("=" * 60)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        print("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant...")
        store = MedicalQdrantStore(url=args.qdrant_url)

        if not store.ping():
            print(f"‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Qdrant: {args.qdrant_url}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω: docker run -p 6333:6333 qdrant/qdrant")
            return

        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        embedder = MedicalEmbedder(args.model)
        print(f"‚úì –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {embedder.get_vector_size()}")

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        print(f"\n–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é {len(json_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        results = index_medical_documents(
            store,
            embedder,
            json_files,
            recreate_collections=args.recreate
        )

        print("\n" + "=" * 60)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´")
        print("=" * 60)

        if 'error' in results:
            print(f"‚ùå –û—à–∏–±–∫–∞: {results['error']}")
            return

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è–º
        for collection_type in ['registry', 'overview', 'sections']:
            if collection_type in results:
                collection_info = results[collection_type]
                print(f"‚úì {collection_info['collection']}: {collection_info['indexed']} –∑–∞–ø–∏—Å–µ–π")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        summary = results.get('summary', {})
        print(f"\n–í—Å–µ–≥–æ:")
        print(f"  –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {summary.get('total_documents', 0)}")
        print(f"  –í–µ–∫—Ç–æ—Ä–æ–≤: {summary.get('total_vectors', 0)}")
        print(f"  –ö–æ–ª–ª–µ–∫—Ü–∏–π: {summary.get('collections_created', 0)}")

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö
        collections_info = store.get_collections_info()
        print(f"\n–ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–ª–ª–µ–∫—Ü–∏–π:")
        for collection, count in collections_info.items():
            print(f"  {collection}: {count} —Ç–æ—á–µ–∫")

        print(f"\nüéâ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"\n–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ:")
        print(f"  1. –ó–∞–ø—É—Å—Ç–∏—Ç—å MCP —Å–µ—Ä–≤–µ—Ä: python medical_mcp_server.py")
        print(
            f"  2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫: python -c \"from usage_example import demo_medical_workflow; import asyncio; asyncio.run(demo_medical_workflow())\"")

    except KeyboardInterrupt:
        print("\n\n‚ùå –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())